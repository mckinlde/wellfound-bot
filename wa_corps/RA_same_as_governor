# ccfs_lookup.py
import csv
import time
from pathlib import Path

from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

from utils.driver_session import start_driver
from utils.SPA_utils import wait_scroll_interact

CSV_PATH = Path("constants/Business Search Result.csv")
OUTPUT_PATH = Path("constants/Business Details.csv")

URL = "https://ccfs.sos.wa.gov/#/Home"

FIELDNAMES = [
    "UBI", "Business ID", "Business Name", "Business Type", "Status",
    "Registered Agent", "Principal Office", "Mailing Address",
    "Nature of Business", "Governors", "Filing History", "Detail URL"
]


def read_ubi_numbers():
    """Read UBI numbers from your input CSV."""
    with open(CSV_PATH, newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            ubi = row["UBI#"].strip()
            if ubi:
                yield ubi


def get_already_processed():
    """
    Return set of UBIs where Governors (detail fields) are already filled in,
    so we can skip only completed rows.
    """
    if not OUTPUT_PATH.exists():
        return set()

    processed = set()
    with open(OUTPUT_PATH, newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            ubi = row.get("UBI")
            governors = row.get("Governors", "").strip()
            if ubi and governors:  # only count as processed if Governors populated
                processed.add(ubi)
    return processed


def process_ubi(ubi):
    # First session: cache links
    with start_driver() as driver:
        links = cache_business_links(driver, ubi)

    # Second session: scrape detail pages
    results = []
    with start_driver() as driver:
        for link in links:
            print(f"[INFO] Fetching {link['Business Name']} at {link['Detail URL']}")
            driver.get(link["Detail URL"])
            WebDriverWait(driver, 20).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "div.businessDetail"))
            )
            html = driver.page_source
            details = parse_business_detail(html)
            details.update(link)  # merge cached info
            results.append(details)
    return results


def parse_business_detail(html):
    from bs4 import BeautifulSoup
    soup = BeautifulSoup(html, "html.parser")

    details = {}

    def safe_text(sel):
        el = soup.select_one(sel)
        return el.get_text(strip=True) if el else None

    # Core business info
    details["Business Name"] = safe_text("div.businessDetail h3")
    details["Status"] = safe_text("div.businessDetail span.status")

    # Registered agent
    details["Registered Agent"] = safe_text("div#registeredAgent span.ng-binding")

    # Principal office / mailing addresses
    details["Principal Office"] = safe_text("div#principalOffice")
    details["Mailing Address"] = safe_text("div#mailingAddress")

    # Nature of business (if present)
    details["Nature of Business"] = safe_text("div#natureOfBusiness")

    # Governors table
    governors = []
    for row in soup.select("table#governors tbody tr"):
        governors.append([td.get_text(strip=True) for td in row.select("td")])
    details["Governors"] = governors

    # Filing history
    filings = []
    for row in soup.select("table#filingHistory tbody tr"):
        filings.append([td.get_text(strip=True) for td in row.select("td")])
    details["Filing History"] = filings

    return details


def cache_business_links(driver, ubi):
    driver.get(URL)

    # Search by UBI
    wait_scroll_interact(driver, by=By.CSS_SELECTOR, selector="input#UBINumber",
                         action="send_keys", keys=ubi)
    wait_scroll_interact(driver, by=By.CSS_SELECTOR, selector="button.btn-search",
                         action="click")

    WebDriverWait(driver, 20).until(
        EC.presence_of_all_elements_located((By.CSS_SELECTOR, "table tbody tr"))
    )

    links = []
    rows = driver.find_elements(By.CSS_SELECTOR, "table tbody tr")
    for row in rows:
        link = row.find_element(By.CSS_SELECTOR, "td a")
        business_name = link.text.strip()
        cells = [td.text.strip() for td in row.find_elements(By.CSS_SELECTOR, "td")]

        # Extract BusinessID and BusinessType from ng-click
        import re
        ng_click = link.get_attribute("ng-click")
        match = re.search(r"showBusineInfo\((\d+),\s*'([^']+)'\)", ng_click)
        if not match:
            continue
        business_id, business_type = match.groups()

        detail_url = f"https://ccfs.sos.wa.gov/#/BusinessSearch/BusinessInformation/{business_id}"

        links.append({
            "UBI": ubi,
            "Business Name": business_name,
            "Business Type": business_type,
            "Business ID": business_id,
            "Detail URL": detail_url,
            "Status": cells[-1] if cells else None,
        })

    return links


def write_results(results):
    """Append results to CSV, writing header if needed."""
    file_exists = OUTPUT_PATH.exists()

    with open(OUTPUT_PATH, "a", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=FIELDNAMES)
        if not file_exists:
            writer.writeheader()
        for r in results:
            writer.writerow({
                **r,
                "Governors": "; ".join([", ".join(g) for g in r.get("Governors", [])]),
                "Filing History": "; ".join([", ".join(f) for f in r.get("Filing History", [])]),
            })


def main():
    processed = get_already_processed()
    print(f"[INFO] Already processed {len(processed)} UBIs.")

    for ubi in read_ubi_numbers():
        if ubi in processed:
            print(f"[SKIP] UBI {ubi} already processed.")
            continue

        print(f"[INFO] Processing UBI {ubi}...")
        try:
            results = process_ubi(ubi)
            write_results(results)
            print(f"[INFO] Wrote {len(results)} records for UBI {ubi}")
        except Exception as e:
            print(f"[ERROR] Failed for {ubi}: {e}")


if __name__ == "__main__":
    main()
